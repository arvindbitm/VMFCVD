{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Model Training with FDM\\n\")\n",
    "\n",
    "fastX_Train = None\n",
    "fastY_Train = None\n",
    "fastX_Test = None\n",
    "fastY_Test = None\n",
    "\n",
    "fastX_Train = pd.DataFrame(X_TrainMaster[fastestFeatures]).copy()\n",
    "fastX_Test = pd.DataFrame(X_TestMaster[fastestFeatures]).copy()\n",
    "fastY_Train = pd.DataFrame(Y_TrainMaster).copy()\n",
    "fastY_Test = pd.DataFrame(Y_TestMaster).copy()\n",
    "\n",
    "fastModels = []\n",
    "\n",
    "fastModels.append(('AdaBoost', AdaBoostClassifier()))\n",
    "fastModels.append(('Bagging', BaggingClassifier()))\n",
    "fastModels.append(('GradientBoost', GradientBoostingClassifier(learning_rate=0.1, n_estimators=100,max_depth=3)))\n",
    "fastModels.append(('KNN', KNeighborsClassifier(n_jobs=-1)))\n",
    "fastModels.append(('RandomForest', RandomForestClassifier(max_depth=4,n_estimators=275)))\n",
    "\n",
    "fastTestVoting = 0\n",
    "fastTotAccuracy = 0\n",
    "fastAccuracyVoting = 0\n",
    "for name, v in fastModels:\n",
    "    v = v.fit(fastX_Train, fastY_Train)\n",
    "    predict = v.predict(fastX_Test)\n",
    "    accuracy = metrics.accuracy_score(fastY_Test, predict)\n",
    "    scores = cross_val_score(v, fastX_Test, fastY_Test)\n",
    "    print(name , ' Accuracy ', accuracy, \" Mean score\", scores.mean())\n",
    "        \n",
    "    fastTotAccuracy = fastTotAccuracy + accuracy       \n",
    "    fastAccuracyVoting = fastAccuracyVoting + (predict * accuracy)\n",
    "    \n",
    "    trainPredict = v.predict(fastX_Train)\n",
    "    fastTestVoting = fastTestVoting + (trainPredict * accuracy)\n",
    "\n",
    "FastModelTrainingEND = time.time()\n",
    "fastMidAccuracy = fastTotAccuracy/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model Testing with fasted performing features\\n\")\n",
    "\n",
    "fastFindingMaxIndexData = pd.DataFrame(columns=['fastY_Test','AccuracyVoting','ResAccuracy','Vote'])\n",
    "fastFindingMaxIndexData['fastY_Test'] = fastY_Test[0] \n",
    "fastFindingMaxIndexData['AccuracyVoting'] = fastAccuracyVoting\n",
    "fastVoteIndex = fastMidAccuracy - 2\n",
    "fastMaxIndex= fastVoteIndex\n",
    "fastMaxAccuracy = 0\n",
    "    \n",
    "for i in range(40):\n",
    "    fastFindingMaxIndexData['ResAccuracy'] = np.where(fastFindingMaxIndexData['AccuracyVoting'] >=fastVoteIndex, 1, 0)\n",
    "    fastFindingMaxIndexData['Vote'] = np.where(fastFindingMaxIndexData['fastY_Test'] == fastFindingMaxIndexData['ResAccuracy'], True, False)\n",
    "    fastTotalRecords = len(fastFindingMaxIndexData)\n",
    "    fastCorretPred = fastFindingMaxIndexData['Vote'].sum()\n",
    "    Accuracy = fastCorretPred/fastTotalRecords\n",
    "    if fastMaxAccuracy < Accuracy:\n",
    "        fastMaxAccuracy = Accuracy\n",
    "        fastMaxIndex = fastVoteIndex\n",
    "    fastVoteIndex = fastVoteIndex + .1\n",
    "\n",
    "fastVotingAnalysis = pd.DataFrame(columns=['fastY_Train','AccuracyVoting','ResAccuracy','Vote',''])\n",
    "fastVotingAnalysis['fastY_Test'] = fastY_Test[0] \n",
    "fastVotingAnalysis['AccuracyVoting'] = fastAccuracyVoting\n",
    "fastVotingAnalysis['ResAccuracy'] = np.where(fastVotingAnalysis['AccuracyVoting'] >=fastMaxIndex,1,0)\n",
    "fastVotingAnalysis['Vote'] = np.where(fastVotingAnalysis['fastY_Test'] == fastVotingAnalysis['ResAccuracy'], True, False)\n",
    "\n",
    "fastVotingAnalysis['RawTP'] = np.where(fastVotingAnalysis['fastY_Test'] == 1, \n",
    "                                   np.where(fastVotingAnalysis['ResAccuracy']==1, 1, 0), 0)\n",
    "fastVotingAnalysis['RawTN'] = np.where(fastVotingAnalysis['fastY_Test'] == 0, \n",
    "                                   np.where(fastVotingAnalysis['ResAccuracy']==0, 1, 0), 0)\n",
    "fastVotingAnalysis['RawFP'] = np.where(fastVotingAnalysis['fastY_Test'] == 0, \n",
    "                                   np.where(fastVotingAnalysis['ResAccuracy']==1, 1, 0), 0)\n",
    "fastVotingAnalysis['RawFN'] = np.where(fastVotingAnalysis['fastY_Test'] == 1, \n",
    "                                   np.where(fastVotingAnalysis['ResAccuracy']==0, 1, 0), 0)\n",
    "\n",
    "fastTotalRecords = len(fastVotingAnalysis)\n",
    "fastCorretPred = fastVotingAnalysis['Vote'].sum()\n",
    "TP = fastVotingAnalysis['RawTP'].sum()\n",
    "TN = fastVotingAnalysis['RawTN'].sum()\n",
    "FP = fastVotingAnalysis['RawFP'].sum()\n",
    "FN = fastVotingAnalysis['RawFN'].sum()\n",
    "\n",
    "print(\"Total Records: \" , fastTotalRecords)\n",
    "print(\"Corret Prediction: \" , fastCorretPred)\n",
    "print(\"True Positive (TP):  \" , TP)\n",
    "print(\"True Negative (TN):  \" , TN)\n",
    "print(\"False Positive (FP): \" , FP)\n",
    "print(\"False Negative (FN): \" , FN)\n",
    "\n",
    "Accuracy = fastCorretPred/fastTotalRecords\n",
    "Precision = TP/(TP+FP)\n",
    "Sensitivity = TP/(TP+FN)\n",
    "F1Score = 2* ((Precision*Sensitivity)/(Precision+Sensitivity))\n",
    "\n",
    "print(\"\\nAccuracy    : \", Accuracy)\n",
    "print(\"Precision   : \", Precision)\n",
    "print(\"Sensitivity : \", Sensitivity)\n",
    "print(\"F1 Score    : \", F1Score )\n",
    "\n",
    "FastVotingEND = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model Testing with DFDM \\n\")\n",
    "\n",
    "fastVotingAnalysis = pd.DataFrame(columns=['fastY_Train','AccuracyVoting','ResAccuracy','Vote',''])\n",
    "fastVotingAnalysis['fastY_Test'] = fastY_Test[0] \n",
    "fastVotingAnalysis['AccuracyVoting'] = fastAccuracyVoting\n",
    "fastVotingAnalysis['ResAccuracy'] = np.where(fastVotingAnalysis['AccuracyVoting'] >=4,1,0)\n",
    "fastVotingAnalysis['Vote'] = np.where(fastVotingAnalysis['fastY_Test'] == fastVotingAnalysis['ResAccuracy'], True, False)\n",
    "\n",
    "fastVotingAnalysis['RawTP'] = np.where(fastVotingAnalysis['fastY_Test'] == 1, \n",
    "                                   np.where(fastVotingAnalysis['ResAccuracy']==1, 1, 0), 0)\n",
    "fastVotingAnalysis['RawTN'] = np.where(fastVotingAnalysis['fastY_Test'] == 0, \n",
    "                                   np.where(fastVotingAnalysis['ResAccuracy']==0, 1, 0), 0)\n",
    "fastVotingAnalysis['RawFP'] = np.where(fastVotingAnalysis['fastY_Test'] == 0, \n",
    "                                   np.where(fastVotingAnalysis['ResAccuracy']==1, 1, 0), 0)\n",
    "fastVotingAnalysis['RawFN'] = np.where(fastVotingAnalysis['fastY_Test'] == 1, \n",
    "                                   np.where(fastVotingAnalysis['ResAccuracy']==0, 1, 0), 0)\n",
    "\n",
    "fastTotalRecords = len(fastVotingAnalysis)\n",
    "fastCorretPred = fastVotingAnalysis['Vote'].sum()\n",
    "TP = fastVotingAnalysis['RawTP'].sum()\n",
    "TN = fastVotingAnalysis['RawTN'].sum()\n",
    "FP = fastVotingAnalysis['RawFP'].sum()\n",
    "FN = fastVotingAnalysis['RawFN'].sum()\n",
    "\n",
    "print(\"Total Records: \" , fastTotalRecords)\n",
    "print(\"Corret Prediction: \" , fastCorretPred)\n",
    "print(\"True Positive (TP):  \" , TP)\n",
    "print(\"True Negative (TN):  \" , TN)\n",
    "print(\"False Positive (FP): \" , FP)\n",
    "print(\"False Negative (FN): \" , FN)\n",
    "\n",
    "Accuracy = fastCorretPred/fastTotalRecords\n",
    "Precision = TP/(TP+FP)\n",
    "Sensitivity = TP/(TP+FN)\n",
    "F1Score = 2* ((Precision*Sensitivity)/(Precision+Sensitivity))\n",
    "\n",
    "print(\"\\nAccuracy    : \", Accuracy)\n",
    "print(\"Precision   : \", Precision)\n",
    "print(\"Sensitivity : \", Sensitivity)\n",
    "print(\"F1 Score    : \", F1Score )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AccuX_Train = None\n",
    "AccuY_Train = None\n",
    "AccuX_Test = None\n",
    "AccuY_Test = None\n",
    "\n",
    "AccuX_Train = pd.DataFrame(X_TrainMaster[mostAccurateFeatures]).copy()\n",
    "AccuX_Test = pd.DataFrame(X_TestMaster[mostAccurateFeatures]).copy()\n",
    "AccuY_Train = pd.DataFrame(Y_TrainMaster).copy()\n",
    "AccuY_Test = pd.DataFrame(Y_TestMaster).copy()\n",
    "\n",
    "AccuModels = []\n",
    "\n",
    "if(noOfModels==2):\n",
    "    print(\"Model Training with most accurate features\")\n",
    "    AccuModels.append(('AdaBoost', AdaBoostClassifier()))\n",
    "    AccuModels.append(('Bagging', BaggingClassifier()))\n",
    "    AccuModels.append(('GradientBoost', GradientBoostingClassifier(learning_rate=0.1, n_estimators=100,max_depth=3)))\n",
    "    AccuModels.append(('KNN', KNeighborsClassifier(n_jobs=-1)))\n",
    "    AccuModels.append(('RandomForest', RandomForestClassifier(max_depth=4,n_estimators=275)))\n",
    "    \n",
    "    AccuTestVoting = 0\n",
    "    AccuTotAccuracy = 0\n",
    "    AccuAccuracyVoting = 0\n",
    "    for name, v in AccuModels:\n",
    "        v = v.fit(AccuX_Train, AccuY_Train)\n",
    "        predict = v.predict(AccuX_Test)\n",
    "        accuracy = metrics.accuracy_score(AccuY_Test, predict)\n",
    "        scores = cross_val_score(v, AccuX_Test, AccuY_Test)\n",
    "        print(name , ' Accuracy ', accuracy, \" Mean score\", scores.mean())\n",
    "\n",
    "        AccuTotAccuracy = AccuTotAccuracy + accuracy       \n",
    "        AccuAccuracyVoting = AccuAccuracyVoting + (predict * accuracy)  \n",
    "        \n",
    "        trainPredict = v.predict(AccuX_Train)\n",
    "        AccuTestVoting = AccuTestVoting + (trainPredict * accuracy)\n",
    "\n",
    "    AccuMidAccuracy = AccuTotAccuracy/2\n",
    "AccuModelTrainingEND = time.time()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(noOfModels==2): \n",
    "    print(\"Model Tesing with fasted performing features\")\n",
    "    AccuFindingMaxIndexData = pd.DataFrame(columns=['AccuY_Test','AccuracyVoting','ResAccuracy','Vote'])\n",
    "    AccuFindingMaxIndexData['AccuY_Test'] = AccuY_Test[0] \n",
    "    AccuFindingMaxIndexData['AccuracyVoting'] = AccuAccuracyVoting\n",
    "    AccuVoteIndex = AccuMidAccuracy - 1\n",
    "    AccuMaxIndex= AccuVoteIndex\n",
    "    AccuMaxAccuracy = 0\n",
    "    for i in range(21):\n",
    "        AccuFindingMaxIndexData['ResAccuracy'] = np.where(AccuFindingMaxIndexData['AccuracyVoting'] >=AccuVoteIndex, 1, 0)\n",
    "        AccuFindingMaxIndexData['Vote'] = np.where(AccuFindingMaxIndexData['AccuY_Test'] == AccuFindingMaxIndexData['ResAccuracy'], True, False)\n",
    "        AccuTotalRecords = len(AccuFindingMaxIndexData)\n",
    "        AccuCorretPred = AccuFindingMaxIndexData['Vote'].sum()\n",
    "        Accuracy = AccuCorretPred/AccuTotalRecords\n",
    "        if AccuMaxAccuracy < Accuracy:\n",
    "            AccuMaxAccuracy = Accuracy\n",
    "            AccuMaxIndex = AccuVoteIndex\n",
    "        AccuVoteIndex = AccuVoteIndex + .1\n",
    "\n",
    "    AccuVotingAnalysis = pd.DataFrame(columns=['AccuY_Train','AccuracyVoting','ResAccuracy','Vote',''])\n",
    "    AccuVotingAnalysis['AccuY_Test'] = AccuY_Test[0] \n",
    "    AccuVotingAnalysis['AccuracyVoting'] = AccuAccuracyVoting\n",
    "    AccuVotingAnalysis['ResAccuracy'] = np.where(AccuVotingAnalysis['AccuracyVoting'] >=AccuMaxIndex,1,0)\n",
    "    AccuVotingAnalysis['Vote'] = np.where(AccuVotingAnalysis['AccuY_Test'] == AccuVotingAnalysis['ResAccuracy'], True, False)\n",
    "\n",
    "    AccuVotingAnalysis['RawTP'] = np.where(AccuVotingAnalysis['AccuY_Test'] == 1, \n",
    "                                       np.where(AccuVotingAnalysis['ResAccuracy']==1, 1, 0), 0)\n",
    "    AccuVotingAnalysis['RawTN'] = np.where(AccuVotingAnalysis['AccuY_Test'] == 0, \n",
    "                                       np.where(AccuVotingAnalysis['ResAccuracy']==0, 1, 0), 0)\n",
    "    AccuVotingAnalysis['RawFP'] = np.where(AccuVotingAnalysis['AccuY_Test'] == 0, \n",
    "                                       np.where(AccuVotingAnalysis['ResAccuracy']==1, 1, 0), 0)\n",
    "    AccuVotingAnalysis['RawFN'] = np.where(AccuVotingAnalysis['AccuY_Test'] == 1, \n",
    "                                       np.where(AccuVotingAnalysis['ResAccuracy']==0, 1, 0), 0)\n",
    "\n",
    "    AccuTotalRecords = len(AccuVotingAnalysis)\n",
    "    AccuCorretPred = AccuVotingAnalysis['Vote'].sum()\n",
    "    TP = AccuVotingAnalysis['RawTP'].sum()\n",
    "    TN = AccuVotingAnalysis['RawTN'].sum()\n",
    "    FP = AccuVotingAnalysis['RawFP'].sum()\n",
    "    FN = AccuVotingAnalysis['RawFN'].sum()\n",
    "\n",
    "    print(\"Total Records: \" , AccuTotalRecords)\n",
    "    print(\"Corret Prediction: \" , AccuCorretPred)\n",
    "    print(\"True Positive (TP):  \" , TP)\n",
    "    print(\"True Negative (TN):  \" , TN)\n",
    "    print(\"False Positive (FP): \" , FP)\n",
    "    print(\"False Negative (FN): \" , FN)\n",
    "\n",
    "    Accuracy = AccuCorretPred/AccuTotalRecords\n",
    "    Precision = TP/(TP+FP)\n",
    "    Sensitivity = TP/(TP+FN)\n",
    "    F1Score = 2* ((Precision*Sensitivity)/(Precision+Sensitivity))\n",
    "\n",
    "    print(\"\\nAccuracy    : \", Accuracy)\n",
    "    print(\"Precision   : \", Precision)\n",
    "    print(\"Sensitivity : \", Sensitivity)\n",
    "    print(\"F1 Score    : \", F1Score )\n",
    "\n",
    "AccuVotingEND = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTotal Time:                        \", int(AccuVotingEND- APPStarted), \"Seconds\")\n",
    "print(\"Data Cleaning Time:                \", int(DataCleanEND- APPStarted), \"Seconds\")\n",
    "print(\"Dimensionality Reduction Time:     \", int(drEND - DataCleanEND), \"Seconds\")\n",
    "print(\"Feature Selection Time:            \", int(FutIdentEND-drEND), \"Seconds\")\n",
    "print(\"Fastest Model Training Time:       \", int(FastModelTrainingEND - FutIdentEND), \"Seconds\")\n",
    "print(\"Fastest Model Testing Time:        \", int(FastVotingEND-FastModelTrainingEND), \"Seconds\")\n",
    "if(noOfModels==2):\n",
    "    print(\"Most Accurate Model Training Time: \", int(AccuModelTrainingEND - FastVotingEND), \"Seconds\")\n",
    "    print(\"Most Accurate Model Testing Time:  \", int(AccuVotingEND - AccuModelTrainingEND), \"Seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
